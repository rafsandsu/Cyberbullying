{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f23e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of cyberbullying words. In a real application, this should be more comprehensive.\n",
    "gender_cyberbullying_words = [\n",
    "    \"Girly\",\n",
    "    \"Manly\",\n",
    "    \"Feminazi\",\n",
    "    \"Sissy\",\n",
    "    \"Man-hater\",\n",
    "    \"Girlboss\",\n",
    "    \"She-male\",\n",
    "    \"Male chauvinist\",\n",
    "    \"Mansplaining\",\n",
    "    \"Man-flu\",\n",
    "    \"Womanizer\",\n",
    "    \"Slut-shaming\",\n",
    "    \"Beta male\",\n",
    "    \"Prude\",\n",
    "    \"Frigid\",\n",
    "    \"Drama queen\",\n",
    "    \"Bitchy\",\n",
    "    \"Tomboy\",\n",
    "    \"Effeminate\",\n",
    "    \"Hysterical\",\n",
    "    \"Butch\",\n",
    "    \"Gold-digger\",\n",
    "    \"Cougar\",\n",
    "    \"Ball-buster\",\n",
    "    \"Spinster\",\n",
    "    \"Old maid\",\n",
    "    \"Cat lady\",\n",
    "    \"Trophy wife\",\n",
    "    \"MILF\",\n",
    "    \"Barbie\",\n",
    "    \"Queen Bee\",\n",
    "    \"White knight\",\n",
    "    \"Incel\",\n",
    "    \"Simp\",\n",
    "    \"Nag\",\n",
    "    \"Baby-maker\",\n",
    "    \"MGTOW\",\n",
    "    \"Macho\",\n",
    "    \"Alpha male\",\n",
    "    \"Body-shaming\",\n",
    "    \"Emasculate\",\n",
    "    \"Bro\",\n",
    "    \"Fag\",\n",
    "    \"Transphobe\",\n",
    "    \"Girly-man\",\n",
    "    \"Wimp\",\n",
    "    \"Bossy\",\n",
    "    \"Frumpy\",\n",
    "    \"Slut\",\n",
    "    \"Dyke\"\n",
    "]\n",
    "\n",
    "religion_cyberbullying_words = [\n",
    "    \"Heretic\",\n",
    "    \"Heathen\",\n",
    "    \"Infidel\",\n",
    "    \"Pagan\",\n",
    "    \"Idolater\",\n",
    "    \"Godless\",\n",
    "    \"Cultist\",\n",
    "    \"Fanatic\",\n",
    "    \"Zealot\",\n",
    "    \"Hypocrite\",\n",
    "    \"Blasphemer\",\n",
    "    \"Apostate\",\n",
    "    \"Unbeliever\",\n",
    "    \"Proselytizer\",\n",
    "    \"Sinner\",\n",
    "    \"Kafir\",\n",
    "    \"Sectarian\",\n",
    "    \"Nonbeliever\",\n",
    "    \"Philistine\",\n",
    "    \"Atheist\",\n",
    "    \"Agnostic\",\n",
    "    \"Deist\",\n",
    "    \"Freethinker\",\n",
    "    \"Sacrilegious\",\n",
    "    \"Unsaved\",\n",
    "    \"Irreligious\",\n",
    "    \"Jihadist\",\n",
    "    \"Fundamentalist\",\n",
    "    \"Extremist\",\n",
    "    \"Puritan\",\n",
    "    \"Legalist\",\n",
    "    \"Papist\",\n",
    "    \"Bible-thumper\",\n",
    "    \"Hare Krishna\",\n",
    "    \"Moonie\",\n",
    "    \"Anti-Semitic\",\n",
    "    \"Anti-Christian\",\n",
    "    \"Anti-Muslim\",\n",
    "    \"Anti-Hindu\",\n",
    "    \"Anti-Buddhist\",\n",
    "    \"Anti-Sikh\",\n",
    "    \"Anti-Atheist\",\n",
    "    \"Anti-Catholic\",\n",
    "    \"Anti-Protestant\",\n",
    "    \"Anti-Mormon\",\n",
    "    \"Anti-Jehovah's Witness\",\n",
    "    \"Anti-Shinto\",\n",
    "    \"Anti-Baha'i\",\n",
    "    \"Anti-Zoroastrian\",\n",
    "    \"Anti-Jain\"\n",
    "]\n",
    "\n",
    "age_cyberbullying_words = [\n",
    "    \"Old fart\",\n",
    "    \"Granny\",\n",
    "    \"Grandpa\",\n",
    "    \"Wrinkly\",\n",
    "    \"Dinosaur\",\n",
    "    \"Fossil\",\n",
    "    \"Geriatric\",\n",
    "    \"Oldie\",\n",
    "    \"Over the hill\",\n",
    "    \"Antique\",\n",
    "    \"Has-been\",\n",
    "    \"Prune\",\n",
    "    \"Baldy\",\n",
    "    \"Ancient\",\n",
    "    \"Old bag\",\n",
    "    \"Codger\",\n",
    "    \"Fuddy-duddy\",\n",
    "    \"Old goat\",\n",
    "    \"Baby\",\n",
    "    \"Toddler\",\n",
    "    \"Kiddo\",\n",
    "    \"Brat\",\n",
    "    \"Snot-nosed\",\n",
    "    \"Punk\",\n",
    "    \"Minor\",\n",
    "    \"Juvenile\",\n",
    "    \"Kidult\",\n",
    "    \"Teenybopper\",\n",
    "    \"Whippersnapper\",\n",
    "    \"Green\",\n",
    "    \"Inexperienced\",\n",
    "    \"Wet behind the ears\",\n",
    "    \"Rookie\",\n",
    "    \"Pup\",\n",
    "    \"Cub\",\n",
    "    \"Newbie\",\n",
    "    \"Novice\",\n",
    "    \"Tenderfoot\",\n",
    "    \"Freshman\",\n",
    "    \"Neophyte\",\n",
    "    \"Tyro\",\n",
    "    \"Greenhorn\",\n",
    "    \"Boy\",\n",
    "    \"Girl\",\n",
    "    \"Childish\",\n",
    "    \"Immature\",\n",
    "    \"Youthful\",\n",
    "    \"Junior\",\n",
    "    \"Old-timer\",\n",
    "    \"Elderly\"\n",
    "]\n",
    "\n",
    "ethnicity_cyberbullying = [\n",
    "    \"Racism\", \"Discrimination\", \"Bigotry\", \"Stereotyping\", \"Xenophobia\", \n",
    "    \"Harassment\", \"Trolling\", \"Cyberstalking\", \"Hate speech\", \"Prejudice\", \n",
    "    \"Ethnic slurs\", \"Marginalization\", \"Intolerance\", \"Derogatory language\", \n",
    "    \"Misrepresentation\", \"Insults\", \"Defamation\", \"Ethnic bias\", \"Ignorance\", \n",
    "    \"Intimidation\", \"Threats\", \"Cultural appropriation\", \"Online abuse\", \"Mockery\", \n",
    "    \"Racial profiling\", \"Exclusion\", \"Disrespect\", \"Offensive content\", \"Bullying\", \n",
    "    \"Victim-blaming\", \"Gaslighting\", \"Outing\", \"Cyber-mobbing\", \"Colorism\", \n",
    "    \"Ethnocentrism\", \"Racial stereotypes\", \"Digital divide\", \"Cyberbullying prevention\", \n",
    "    \"Reporting tools\", \"Victim support\", \"Consent\", \"Cyber-etiquette\", \"Anonymity\", \n",
    "    \"Bystander effect\", \"Microaggressions\", \"Cultural insensitivity\", \"Safe space\", \n",
    "    \"Empathy\", \"Legal recourse\", \"Digital footprint\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset.\n",
    "# Assume the dataset is a CSV file with a 'text' column that contains the text to be checked.\n",
    "df = pd.read_csv('cyberbullying_features.csv')\n",
    "\n",
    "# Function to check if a text is cyberbullying\n",
    "def is_cyberbullying(text):\n",
    "    for word in gender_cyberbullying_words:\n",
    "        if word in text.lower():  # Convert text to lower case to match case-insensitively\n",
    "            return 'Gender based cyberbullying'\n",
    "    for word in religion_cyberbullying_words:\n",
    "        if word in text.lower():\n",
    "            return 'Religion based cyberbullying'\n",
    "    for word in age_cyberbullying_words:\n",
    "        if word in text.lower():\n",
    "            reutrn 'Age based cyberbullying'\n",
    "    for word in ethnicity_cyberbullying:\n",
    "        if word in text.lower():\n",
    "            return 'Ethnicity based cyberbullying'\n",
    "    return 'noncyberbullying'  # If none of the words match, it's not cyberbullying\n",
    "\n",
    "# Apply the function to each row in the dataset\n",
    "df['label'] = df['tweet_text'].apply(is_cyberbullying)\n",
    "\n",
    "# Save the updated dataset\n",
    "df.to_csv('labelled_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54568b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
